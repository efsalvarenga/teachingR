---
title: 'Learning R Chapter 2'
subtitle: 'Data Processing'
author: "EFS Alvarenga"
date: "23/07/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
```

## Before starting

The initial task is to get familiarised with the different data object types.

### Vectors

Several functions can be used to create vectors.

```{r}
v1 <- 1                 # vector with length 1
v1
v2 <- c(1,2,3,4)        # basic function for creating (combining) vectors
v2
1:10                    # sequence from 1 to 10
seq(1,10)               # sequence from 1 to 10
seq(1,10, by = 2)       # sequence from 1 to 10, 2 by 2
rep(1,5)                # repeat 1, 5 times
rep(c(1,2,4),5)         # repeat vector c(1,2,4) 5 times
```

### Data types

R can handle several data types.
Vectors and matrices are restricted to use the same type of data in the entire structure, while lists and data frames allow mixed data type structures.

```{r}
vlog  <- c(FALSE, TRUE, FALSE)            # vector of boolean data
vtex  <- c('x', 'key', 'water', 'true')   # vector of strings
vint  <- c(124, 34223, 43, 342)           # vector of integers
vreal <- c(23.4, 34.2, 2, 4.1)           # vector of real numbers
```

If the user (or some function) returns a vector with mixed data types, R will try to fit everything in the more flexible data type possible (generally strings).

```{r}
vmix <- c(1, 2, 'ops')
vmix
```

Many functions are available for testing the data type of a given object.

```{r}
is.logical(vlog)
is.character(vint)
is.character(vmix)
is.numeric(vtex)
```

### Data frames

Data frames are square tables.
Structurally speaking they work like a list of vectors of the same length, with the inherited flexibility of allowing different data types on each column.

```{r}
data.frame(let = c('A','B','C'), num = c(2, 3, 4), logi = c(T, F, T))
data.frame(let = c('A','B','C'),
           num = c(2, 3, 4),
           logi = c(T, F, T))
let = c('A','B','C')
num = c(2, 3, 4)
logi = c(T, F, T)
data.frame(let, num, logi)
```

Notice different ways of building the same object in R (as in many programming languages)/
Also notice we use `<-` for assigning values to an object, while `=` was used for assigning values to arguments within function calls.
This is a aesthetic decision as `=` can also be used for assigning values to objects.

### Saving and loading data frames

Data frames are flexible structures but still hold restrictions that allow them to be easily saved and loaded as simple table files.
CSV files are preferable given their easy interpretation in many applications and OS's.

```{r}
df1 <- data.frame(A = let,
                  B = num,
                  C = logi)
df1
write.table(x = df1,
            file = '../data/df1.csv',
            sep = ';',
            row.names = FALSE)
df2 <- read.table(file = '../data/df1.csv',
                  sep = ';',
                  header = TRUE)
df2
```

## Data processig using Base R

The function `read.csv()` and `read.csv2()` are sister functions of the `read.table()` used before and can be used to load many data sources.
Other file types can also be imported, such as MS Excel spreadsheets (through the `readxl` and many others), SQL queries, etc.
For further information of how to import specific file types, please see [This R Data Import Tutorial Is Everything You Need](https://www.datacamp.com/community/tutorials/r-data-import-tutorial).

You will be importing a simplified dataset for the next steps on this tutorial.
This dataset contains the historical energy generation for a few countries (in GWh).

```{r}
energy_gen <- read.csv(file = 'https://www.dropbox.com/s/tdzpd8rsnweeoo2/EnergyDataLight.csv?dl=1')
```

There are many functions to examine imported (or generated) datasets.

```{r}
head(energy_gen)                   # examine the first lines of an object
energy_gen[1:10,c(1,3:5)]          # examine subsets of an object
is.data.frame(energy_gen)          # check if the object is a data frame
dim(energy_gen)                    # check an object's dimensions
str(energy_gen)                    # check the objects's structure
summary(energy_gen)                # descriptive statistics of columns
energy_gen$NLD                     # extract a vector from a specific column
energy_gen[,2]                     # the same operation as before, using subsets
```

```{r eval=FALSE, include=TRUE}
View(energy_gen)                   # open the object viewer in a new tab
```

We can apply mathematical (statistical) operations on the dataset.

```{r}
GBRu <- mean(energy_gen$GBR)
GBRu
NLDu <- mean(energy_gen$NLD)
NLDu
NORu <- mean(energy_gen$NOR)
NORu
USAu <- mean(energy_gen$USA)
USAu
```

We can convert the recently created objects (which are of the double type) can be converted as integers.

```{r}
as.integer(GBRu)
as.integer(NLDu)
as.integer(NORu)
as.integer(USAu)
```

We can also perform arithmetic calculations.

```{r}
USAu / GBRu
round(USAu / GBRu, 1)
```

## Data processig using **tidyverse**

_The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures._
Read more about the tidyverse here [https://www.tidyverse.org/](https://www.tidyverse.org/).

```{r eval=FALSE, include=TRUE}
install.packages('tidyverse')
```

We will start using the `dplyr` library from tidyverse.

```{r eval=FALSE, include=TRUE}
library(dplyr)
```

`dplyr` is used for chaining functions in an execution routine.
This schema allows the inversion of a function and its arguments, based of the `%>%` operator from `magittr`.
In this sense, `f(x)` can be presented as `x %>% f`, which makes it easier to read long execution chains.

```{r}
sum(rep(seq(from=4, length=6, by=2), times=2))
seq(from=4, length=6, by=2) %>%
  rep(., times=2) %>%
  sum(.)
```

The "." (dot) is interpreted as the result of the previous execution being called as the argument, and it can be omitted most of the times.

```{r}
seq(from=4, length=6, by=2) %>%
  rep(times=2) %>%
  sum()
```

Beyond the chain operator, `dplyr` uses _verb_ functions for operations such as `filter()`, `group_by()`, `select()`, `summarise()`.

NB. The function `head()` is included as the last in a chain to avoid printing the entire output on the tutorial.
By excluding this last function the output will include the entire table.

```{r}
energy_gen %>%
  head()
energy_gen %>%
  filter(TIME > 2008)
```

From experience I know the `select()` function from `dplyr` has a conflict with another package (functions with the same name, but different execution routines).
To avoid errors the package from which the function will be called can be assigned with the operator `::`.
This way, a robust way of calling the `select()` function is as below.

```{r}
energy_gen %>%
  dplyr::select(TIME,GBR,USA) %>%
  head()
```

The `mutate()` function allows creating (or updating existing) variables.

```{r}
energy_gen %>%
  dplyr::select(TIME,GBR,USA) %>%
  mutate(decade = 10*floor(TIME/10))
```

If, after calculating the decades, we wanted to group by and then calculate averages for each decade, we can observe the energy generation trend over the decades.

```{r}
energy_gen %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  group_by(decade) %>%
  summarise(uGBR = mean(GBR),
            uUSA = mean(USA))
```

Another useful `tidyverse` library for data analytics is the `tidyr`.

```{r eval=FALSE, include=TRUE}
library(tidyr)
```

The `gather()` and `spread()` functions allows the transformation of wide tables (like the one we've been using) into long tables, similar to database encoding.
For more details on this process, visit the [Tidy Data](http://vita.had.co.nz/papers/tidy-data.html) article from Hadley Wickham.

```{r}
energy_gen_long <- energy_gen %>%
  gather(country, generation, -TIME)
energy_gen_long %>% head()
energy_gen_long %>%
  spread(country, generation) %>%
  head()
```

With the long table format running operations is a bit simpler through the `group_by()` function.

```{r}
energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  group_by(decade, country) %>%
  summarise(avgGen = mean(generation))
```

To visualise the same way as before, just use `filter()` for selecting only **GBR** and **USA** and then add the `spread()` in the end.

```{r}
energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  group_by(decade, country) %>%
  summarise(avgGen = mean(generation)) %>%
  filter(country %in% c('GBR','USA')) %>%
  spread(country, avgGen)
```

NB. Wide tables are very useful for human data visualisation.
However, long tables are preferable for computational operations.
For this reason, mastering the `gather()` and `spread()` functions is very handy for data analysis.

The `distinct()` function returns the unique combination of values between all selected columns (or the unique values of a singular column).

```{r}
energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  dplyr::select(decade) %>%
  distinct()
energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  dplyr::select(decade, country) %>%
  distinct() %>%
  head(12)
# I am using the head(12) for brevity on the print version
```


Para organizar os dados em ordem crescente ou decrescente utilize `arrange()` ou `arrange(desc())`, respectivamente.

```{r}
energy_gen_long %>%
  group_by(country) %>%
  summarise(avgGen = mean(generation)) %>%
  arrange(desc(avgGen))
```

Para combinar tabelas distintas em uma única tabela, utilize os **join()** baseados em banco de dados.
_Joins_ são como a função `vlookup()` ou `procv()` do Excel turbinadas!
  Para uma descrição completa dessas operações veja [SQL Joins](https://www.devmedia.com.br/sql-join-entenda-como-funciona-o-retorno-dos-dados/31006).

Para exemplificar, vamos criar duas tabelas baseadas na `energy_gen_long` e executar diversos _joins_.

```{r}
tab1 <- energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  group_by(decade, country) %>%
  summarise(avgGen = mean(generation)) %>%
  filter(country %in% c('USA','GBR','NLD'))
# %in% testa um vetor (ou coluna) para valores contidos em outro vetor
tab1
tab2 <- energy_gen_long %>%
  mutate(decade = 10*floor(TIME/10)) %>%
  group_by(decade, country) %>%
  summarise(avgGen = mean(generation)) %>%
  filter(country %in% c('NOR','NLD'))
tab2
tab1 %>%
  inner_join(tab2)
tab1 %>%
  left_join(tab2)
tab1 %>%
  right_join(tab2)
tab1 %>%
  full_join(tab2)
```

### Exercício sugerido

The file we used so far is actually a simplification of a larger file, available [here](https://www.dropbox.com/s/nx1rd3byrj7gtjv/EnergyData.csv?dl=1)

A good exercise would be to filter and select through this file to make a file as similar as possible to the simplified version we used on this tutorial.

### Observações

#### Lidando com datas (e _datetimes_)

Datas e _datetimes_ são interpretadas de forma diferente entre o Excel e a maior parte das linguagens de programação.
Enquanto o Excel trata a todos como o mesmo tipo de objeto, sendo horas dentro de um dia interpretadas como frações, o R utiliza duas classes distintas.
A classe **Date** (utilize a função `as.Date()` para criar objetos dessa classe) guarda apenas datas, como valores inteiros entre o dia e a origem (definida como 01/01/1970).
Já a classe **POSIXt** (utilize a função `as.POSIXct()` ou `as.POSIXlt()`) guarda horas, minutos e segundos.
Essas classes são altamente intercambiáveis entre si.
Para detalhes , consulte o tutorial [Handling date-times in R](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/ColeBeck/datestimes.pdf) de Cole Beck.
